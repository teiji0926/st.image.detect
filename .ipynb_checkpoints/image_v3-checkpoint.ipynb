{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d56f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import os\n",
    "import azure.ai.vision as sdk\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "# VISION_ENDPOINTの値を設定\n",
    "os.environ[\"VISION_ENDPOINT\"] = \"https://test20231021.cognitiveservices.azure.com/\"\n",
    "os.environ[\"VISION_KEY\"] = \"59c9dbcf9e774a1a99fdd6bb47a716fd\"\n",
    "subscription_key = os.environ[\"VISION_KEY\"]\n",
    "endpoint = os.environ[\"VISION_ENDPOINT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a86e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641f2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#認証\n",
    "#コード内でos.environ[\"VISION_KEY\"]という行を見つけると、subscription_keyは環境変数VISION_KEYから取得する\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31d38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL指定\n",
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9b17f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "print(\"End of Computer Vision quickstart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f61837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'an ancient city with many ruins with Colosseum in the background' with confidence 33.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API with remote image\n",
    "describe_result_remote = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Print the descriptions and confidence values\n",
    "print(\"Description of remote image: \")\n",
    "if (len(describe_result_remote.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in describe_result_remote.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6d1f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories in the remote image: \n",
      "'building_' with confidence 31.64%\n",
      "'others_' with confidence 0.39%\n",
      "'outdoor_' with confidence 3.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Call API with remote image\n",
    "categorize_result_remote = computervision_client.analyze_image(remote_image_url, visual_features=[VisualFeatureTypes.categories])\n",
    "\n",
    "# Print the categories and confidence values\n",
    "print(\"Categories in the remote image: \")\n",
    "if (len(categorize_result_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_result_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df4e26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "print(\"End of Computer Vision quickstart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d1d9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detected objects in remote image: \n",
      "'person' with confidence 53.80% at location 99, 121, 506, 749\n",
      "'academic gown' with confidence 56.10% at location 127, 414, 477, 911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_image_url = \"https://thetv.jp/i/nw/160161/939253.jpg\"\n",
    "\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Call API with remote image\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detected objects in remote image: \")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"'{}' with confidence {:.2f}% at location {}, {}, {}, {}\".format( \\\n",
    "        object.object_property, object.confidence * 100, \\\n",
    "        object.rectangle.x, object.rectangle.y, \\\n",
    "        object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y + object.rectangle.h))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cbf2d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detected objects in local image: \n",
      "'person' with confidence 57.90% at location 5, 23, 202, 232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ローカルファイルから画像データを読み込む\n",
    "image_path = r\"C:\\Users\\teiji\\OneDrive\\Desktop\\kuji.jpg\"  # 画像ファイルへの\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "# Call API with local image\n",
    "detect_objects_results_local = computervision_client.detect_objects_in_stream(image_stream)\n",
    "\n",
    "# 同様に、結果を表示する\n",
    "print(\"Detected objects in local image: \")\n",
    "if len(detect_objects_results_local.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_local.objects:\n",
    "        print(\"'{}' with confidence {:.2f}% at location {}, {}, {}, {}\".format( \\\n",
    "        object.object_property, object.confidence * 100, \\\n",
    "        object.rectangle.x, object.rectangle.y, \\\n",
    "        object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y + object.rectangle.h))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2aa58f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x000001B8CE3CECB0>, 'object_property': 'person', 'confidence': 0.538, 'parent': None}\n",
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x000001B8CE3D0670>, 'object_property': 'academic gown', 'confidence': 0.561, 'parent': <azure.cognitiveservices.vision.computervision.models._models_py3.ObjectHierarchy object at 0x000001B8CE3D09D0>}\n"
     ]
    }
   ],
   "source": [
    "for x in detect_objects_results_remote.objects:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbd31172",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\teiji\\OneDrive\\Desktop\\kuji.jpg\"  # 画像ファイルへの\n",
    "\n",
    "#タグ取得関数\n",
    "def get_tags(file_path):\n",
    "    local_image = open(file_path, \"rb\")\n",
    "    tags_result = computervision_client.tag_image_in_stream(local_image)\n",
    "    tags = tags_result.tags\n",
    "    tags_name = []\n",
    "    #辞書型に見えるけどオブジェクトなので、name属性でとってくる\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "    return tags_name\n",
    "\n",
    "# # Print results with confidence score\n",
    "# print(\"Tags in the remote image: \")\n",
    "# if (len(tags_result.tags) == 0):\n",
    "#     print(\"No tags detected.\")\n",
    "# else:\n",
    "#     for tag in tags_result.tags:\n",
    "#         print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "# print()\n",
    "# '''\n",
    "# END - Tag an Image - remote\n",
    "# '''\n",
    "# print(\"End of Computer Vision quickstart.\")\n",
    "\n",
    "# for tag in tags:\n",
    "#     print(f\"Type of tag object: {type(tag)}\")  # タグオブジェクトのタイプを印刷\n",
    "#     if isinstance(tag, dict):  # タグが辞書の場合\n",
    "#         print(f\"Tag name: {tag['name']}, Confidence: {tag['confidence']}\")\n",
    "#     else:  # タグが辞書でない場合（オブジェクトの場合）\n",
    "#         print(f\"Tag name: {tag.name}, Confidence: {tag.confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb19e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'human face',\n",
       " 'clothing',\n",
       " 'girl',\n",
       " 'black hair',\n",
       " 'smile',\n",
       " 'woman',\n",
       " 'asian',\n",
       " 'indoor']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path =   r\"C:\\Users\\teiji\\OneDrive\\Desktop\\OIP.jpg\"\n",
    "get_tags(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d215e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(file_path): \n",
    "    # Call API with local image\n",
    "    #公式ドキュメントは\n",
    "    image_stream = open(file_path, \"rb\")\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(image_stream)\n",
    "    objects = detect_objects_results.objects\n",
    "    return objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5125d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\teiji\\OneDrive\\Desktop\\kuji.jpg\"  # 画像ファイルへの\n",
    "object = detect_objects(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8358f555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x1c28b937e20>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f30c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
