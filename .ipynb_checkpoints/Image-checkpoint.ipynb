{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5a72b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.ai.vision as sdk\n",
    "\n",
    "\n",
    "# VISION_ENDPOINTの値を設定\n",
    "os.environ[\"VISION_ENDPOINT\"] = \"https://test20231021.cognitiveservices.azure.com/\"\n",
    "os.environ[\"VISION_KEY\"] = \"59c9dbcf9e774a1a99fdd6bb47a716fd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25c7fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fa694ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エンドポイントと認証キーを設定\n",
    "#この時点で認証してる\n",
    "service_options = sdk.VisionServiceOptions(os.environ[\"VISION_ENDPOINT\"],os.environ[\"VISION_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fc529fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageSourceBuffer' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m image_source_buffer \u001b[38;5;241m=\u001b[39m sdk\u001b[38;5;241m.\u001b[39mImageSourceBuffer()\n\u001b[0;32m      8\u001b[0m image_source_buffer\u001b[38;5;241m.\u001b[39mimage_writer\u001b[38;5;241m.\u001b[39mwrite(image_data)\n\u001b[1;32m----> 9\u001b[0m vision_source \u001b[38;5;241m=\u001b[39m \u001b[43msdk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVisionSource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_source_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stleamlit_app\\lib\\site-packages\\azure\\ai\\vision\\vision_base_client.py:410\u001b[0m, in \u001b[0;36mVisionSource.__init__\u001b[1;34m(self, filename, url, image_source_buffer, frame_source, device_attributes)\u001b[0m\n\u001b[0;32m    407\u001b[0m     _call_hr_fn(fn\u001b[38;5;241m=\u001b[39m_sdk_lib\u001b[38;5;241m.\u001b[39mvision_source_handle_create, \u001b[38;5;241m*\u001b[39m[ctypes\u001b[38;5;241m.\u001b[39mbyref(handle), _c_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource.device.attributes\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    408\u001b[0m                 c_device_attributes, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 410\u001b[0m     c_filename \u001b[38;5;241m=\u001b[39m \u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m     _call_hr_fn(fn\u001b[38;5;241m=\u001b[39m_sdk_lib\u001b[38;5;241m.\u001b[39mvision_source_handle_create, \u001b[38;5;241m*\u001b[39m[ctypes\u001b[38;5;241m.\u001b[39mbyref(handle), _c_str(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource.file.name\u001b[39m\u001b[38;5;124m\"\u001b[39m), c_filename,\n\u001b[0;32m    412\u001b[0m                 \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\stleamlit_app\\lib\\site-packages\\azure\\ai\\vision\\interop.py:110\u001b[0m, in \u001b[0;36m_c_str\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageSourceBuffer' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "#解析対象のイメージURLを設定\n",
    "#vision_source = sdk.VisionSource(url=\"https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png\")\n",
    "\n",
    "with open(r\"C:\\Users\\teiji\\OneDrive\\Desktop\\OIP.jpg\", \"rb\") as image_file:\n",
    "    image_data = image_file.read()\n",
    "\n",
    "image_source_buffer = sdk.ImageSourceBuffer()\n",
    "image_source_buffer.image_writer.write(image_data)\n",
    "vision_source = sdk.VisionSource(image_source_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18630697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageAnalysisOptions クラスは、画像解析のオプションや設定を表現するために使用されるクラスであり、\n",
    "#このインスタンスは後に、画像解析器 (ImageAnalyzer) のコンストラクタに渡され、画像解析の動作をカスタマイズするために使用されます。\n",
    "analysis_options = sdk.ImageAnalysisOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5ce7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_options オブジェクトの features プロパティを設定しています\n",
    "#features プロパティは、どの画像解析の特性を有効にするかを指定します。\n",
    "#画像のキャプションは、画像の内容を簡潔かつ明瞭に説明する文やフレーズ\n",
    "#sdk.ImageAnalysisFeature.TEXT:これも画像解析の特性を表す値で、画像内のテキストを抽出する機能\n",
    "analysis_options.features = (sdk.ImageAnalysisFeature.CAPTION | sdk.ImageAnalysisFeature.TEXT | sdk.ImageAnalysisFeature.TAGS | sdk.ImageAnalysisFeature.OBJECTS)\n",
    "#2つの機能をオンにしている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78925829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像内のテキストを英語として認識する設定\n",
    "analysis_options.language = \"en\"\n",
    "#性別の判定をしない（人間と回答）\n",
    "analysis_options.gender_neutral_caption = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "914ffa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdk.ImageAnalyzer クラスの新しいインスタンスは後で画像解析を実行する際に使用されます\n",
    "#service_options = Azure Computer Visionサービスへの接続に必要な認証情報やエンドポイント情報を含みます\n",
    "#vision_source = 解析する画像のソース（このコードの例ではURL）を指定します\n",
    "#analysis_options = 画像解析のオプションや設定を指定します。たとえば、どの特性を解析するか、どの言語を使用するか、ジェンダーを生成するかどうかなどを指定します。\n",
    "image_analyzer = sdk.ImageAnalyzer(service_options, vision_source, analysis_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15874987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze メソッドは、image_analyzer オブジェクトが保持している設定（サービスオプション、ビジョンソース、解析オプション）に基づいて画像解析を実行します。このメソッドは、\n",
    "#Azure Computer Vision サービスにリクエストを送信し、画像のキャプション生成やテキスト抽出などの解析を行います。\n",
    "#result は、analyze メソッドの戻り値を受け取る変数です。この戻り値は、解析された画像のデータやメタデータ、および任意のエラー情報を含むオブジェクトです。この result オブジェクトを通じて、\n",
    "#解析の結果をプログラムで利用することができます。\n",
    "result = image_analyzer.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f99c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Caption:\n",
      "   'a man pointing at a screen', Confidence 0.7768\n",
      " Text:\n",
      "   Line: '9:35 AM', Bounding polygon {130, 129, 215, 130, 215, 149, 130, 148}\n",
      "     Word: '9:35', Bounding polygon {131, 130, 171, 130, 171, 149, 130, 149}, Confidence 0.9930\n",
      "     Word: 'AM', Bounding polygon {179, 130, 204, 130, 203, 149, 178, 149}, Confidence 0.9980\n",
      "   Line: 'E Conference room 154584354', Bounding polygon {130, 153, 224, 154, 224, 161, 130, 161}\n",
      "     Word: 'E', Bounding polygon {131, 154, 135, 154, 135, 161, 131, 161}, Confidence 0.1040\n",
      "     Word: 'Conference', Bounding polygon {142, 154, 174, 154, 173, 161, 141, 161}, Confidence 0.9020\n",
      "     Word: 'room', Bounding polygon {175, 154, 189, 155, 188, 161, 175, 161}, Confidence 0.7960\n",
      "     Word: '154584354', Bounding polygon {192, 155, 224, 154, 223, 162, 191, 161}, Confidence 0.8640\n",
      "   Line: '#: 555-173-4547', Bounding polygon {130, 163, 182, 164, 181, 171, 130, 170}\n",
      "     Word: '#:', Bounding polygon {131, 163, 139, 164, 139, 171, 131, 171}, Confidence 0.0360\n",
      "     Word: '555-173-4547', Bounding polygon {142, 164, 182, 165, 181, 171, 142, 171}, Confidence 0.5970\n",
      "   Line: 'Town Hall', Bounding polygon {546, 180, 590, 180, 590, 190, 546, 190}\n",
      "     Word: 'Town', Bounding polygon {547, 181, 568, 181, 568, 190, 546, 191}, Confidence 0.9810\n",
      "     Word: 'Hall', Bounding polygon {570, 181, 590, 181, 590, 191, 570, 190}, Confidence 0.9910\n",
      "   Line: '9:00 AM - 10:00 AM', Bounding polygon {546, 191, 596, 192, 596, 200, 546, 199}\n",
      "     Word: '9:00', Bounding polygon {546, 192, 555, 192, 555, 200, 546, 200}, Confidence 0.0900\n",
      "     Word: 'AM', Bounding polygon {557, 192, 565, 192, 565, 200, 557, 200}, Confidence 0.9910\n",
      "     Word: '-', Bounding polygon {567, 192, 569, 192, 569, 200, 567, 200}, Confidence 0.6910\n",
      "     Word: '10:00', Bounding polygon {570, 192, 585, 193, 584, 200, 570, 200}, Confidence 0.8850\n",
      "     Word: 'AM', Bounding polygon {586, 193, 593, 194, 593, 200, 586, 200}, Confidence 0.9910\n",
      "   Line: 'Aaron Buaion', Bounding polygon {543, 201, 581, 201, 581, 208, 543, 208}\n",
      "     Word: 'Aaron', Bounding polygon {545, 202, 560, 202, 559, 208, 544, 208}, Confidence 0.6020\n",
      "     Word: 'Buaion', Bounding polygon {561, 202, 580, 202, 579, 208, 560, 208}, Confidence 0.2910\n",
      "   Line: 'Daily SCRUM', Bounding polygon {537, 259, 575, 260, 575, 266, 537, 265}\n",
      "     Word: 'Daily', Bounding polygon {538, 259, 551, 260, 550, 266, 538, 265}, Confidence 0.1750\n",
      "     Word: 'SCRUM', Bounding polygon {552, 260, 570, 260, 570, 266, 551, 266}, Confidence 0.1140\n",
      "   Line: '10:00 AM 11:00 AM', Bounding polygon {536, 266, 590, 266, 590, 272, 536, 272}\n",
      "     Word: '10:00', Bounding polygon {539, 267, 553, 267, 552, 273, 538, 272}, Confidence 0.8570\n",
      "     Word: 'AM', Bounding polygon {554, 267, 561, 267, 560, 273, 553, 273}, Confidence 0.9980\n",
      "     Word: '11:00', Bounding polygon {564, 267, 578, 267, 577, 273, 563, 273}, Confidence 0.4790\n",
      "     Word: 'AM', Bounding polygon {579, 267, 586, 267, 585, 273, 578, 273}, Confidence 0.9940\n",
      "   Line: 'Churlette de Crum', Bounding polygon {538, 273, 584, 273, 585, 279, 538, 279}\n",
      "     Word: 'Churlette', Bounding polygon {539, 274, 562, 274, 561, 279, 538, 279}, Confidence 0.4640\n",
      "     Word: 'de', Bounding polygon {563, 274, 569, 274, 568, 279, 562, 279}, Confidence 0.8100\n",
      "     Word: 'Crum', Bounding polygon {570, 274, 582, 273, 581, 279, 569, 279}, Confidence 0.8850\n",
      "   Line: 'Quarterly NI Hands', Bounding polygon {538, 295, 588, 295, 588, 301, 538, 302}\n",
      "     Word: 'Quarterly', Bounding polygon {540, 296, 562, 296, 562, 302, 539, 302}, Confidence 0.5230\n",
      "     Word: 'NI', Bounding polygon {563, 296, 570, 296, 570, 302, 563, 302}, Confidence 0.3030\n",
      "     Word: 'Hands', Bounding polygon {572, 296, 588, 296, 588, 302, 571, 302}, Confidence 0.6130\n",
      "   Line: '11.00 AM-12:00 PM', Bounding polygon {536, 304, 588, 303, 588, 309, 536, 310}\n",
      "     Word: '11.00', Bounding polygon {538, 304, 552, 304, 552, 310, 538, 310}, Confidence 0.6180\n",
      "     Word: 'AM-12:00', Bounding polygon {554, 304, 578, 304, 577, 310, 553, 310}, Confidence 0.2700\n",
      "     Word: 'PM', Bounding polygon {579, 304, 586, 304, 586, 309, 578, 310}, Confidence 0.6620\n",
      "   Line: 'Bebek Shaman', Bounding polygon {538, 310, 577, 310, 577, 316, 538, 316}\n",
      "     Word: 'Bebek', Bounding polygon {539, 310, 554, 310, 554, 317, 539, 316}, Confidence 0.6110\n",
      "     Word: 'Shaman', Bounding polygon {555, 310, 576, 311, 576, 317, 555, 317}, Confidence 0.6050\n",
      "   Line: 'Weekly stand up', Bounding polygon {537, 332, 582, 333, 582, 339, 537, 338}\n",
      "     Word: 'Weekly', Bounding polygon {538, 332, 557, 333, 556, 339, 538, 338}, Confidence 0.6060\n",
      "     Word: 'stand', Bounding polygon {558, 333, 572, 334, 571, 340, 557, 339}, Confidence 0.4890\n",
      "     Word: 'up', Bounding polygon {574, 334, 580, 334, 580, 340, 573, 340}, Confidence 0.8150\n",
      "   Line: '12:00 PM-1:00 PM', Bounding polygon {537, 340, 583, 340, 583, 347, 536, 346}\n",
      "     Word: '12:00', Bounding polygon {539, 341, 553, 341, 552, 347, 538, 347}, Confidence 0.8260\n",
      "     Word: 'PM-1:00', Bounding polygon {554, 341, 575, 341, 574, 347, 553, 347}, Confidence 0.2090\n",
      "     Word: 'PM', Bounding polygon {576, 341, 583, 341, 582, 347, 575, 347}, Confidence 0.0390\n",
      "   Line: 'Delle Marckre', Bounding polygon {538, 347, 582, 347, 582, 352, 538, 353}\n",
      "     Word: 'Delle', Bounding polygon {540, 348, 559, 347, 558, 353, 539, 353}, Confidence 0.5800\n",
      "     Word: 'Marckre', Bounding polygon {560, 347, 582, 348, 582, 353, 559, 353}, Confidence 0.2750\n",
      "   Line: 'Product review', Bounding polygon {538, 370, 577, 370, 577, 376, 538, 375}\n",
      "     Word: 'Product', Bounding polygon {539, 370, 559, 371, 558, 376, 539, 376}, Confidence 0.6150\n",
      "     Word: 'review', Bounding polygon {560, 371, 576, 371, 575, 376, 559, 376}, Confidence 0.0400\n",
      " Tags:\n",
      "   Tag: text, Confidence: 0.9966\n",
      "   Tag: clothing, Confidence: 0.9801\n",
      "   Tag: person, Confidence: 0.9596\n",
      "   Tag: display device, Confidence: 0.9490\n",
      "   Tag: indoor, Confidence: 0.9475\n",
      "   Tag: wall, Confidence: 0.9396\n",
      "   Tag: media, Confidence: 0.9306\n",
      "   Tag: television set, Confidence: 0.9281\n",
      "   Tag: led-backlit lcd display, Confidence: 0.9255\n",
      "   Tag: flat panel display, Confidence: 0.9209\n",
      "   Tag: furniture, Confidence: 0.9133\n",
      "   Tag: lcd tv, Confidence: 0.8951\n",
      "   Tag: man, Confidence: 0.8884\n",
      "   Tag: television, Confidence: 0.8766\n",
      "   Tag: video, Confidence: 0.8747\n",
      "   Tag: multimedia, Confidence: 0.8719\n",
      "   Tag: output device, Confidence: 0.8586\n",
      "   Tag: computer monitor, Confidence: 0.8442\n",
      "   Tag: table, Confidence: 0.8430\n",
      "   Tag: screen, Confidence: 0.7113\n",
      "   Tag: standing, Confidence: 0.7051\n",
      "   Tag: design, Confidence: 0.4042\n",
      "   Tag: person, Confidence: 0.9050\n",
      "   Bounding box: 655, 83, 263, 605\n",
      "   Tag: television, Confidence: 0.8080\n",
      "   Bounding box: 75, 76, 678, 414\n"
     ]
    }
   ],
   "source": [
    "#sdk.ImageAnalysisResultReason.ANALYZEDは画像解析が成功し、結果が利用可能であることを示す定数値\n",
    "#reason プロパティは、画像解析の結果のステータスを表す値を含んでいます。\n",
    "#これは、画像解析が成功した、または何らかのエラーが発生したかどうかを示す値\n",
    "if result.reason == sdk.ImageAnalysisResultReason.ANALYZED:\n",
    "    if result.caption is not None:\n",
    "        print(\" Caption:\")\n",
    "        print(\"   '{}', Confidence {:.4f}\".format(result.caption.content, result.caption.confidence))\n",
    "    if result.text is not None:\n",
    "        print(\" Text:\")\n",
    "        for line in result.text.lines:\n",
    "            points_string = \"{\" + \", \".join([str(int(point)) for point in line.bounding_polygon]) + \"}\"\n",
    "            print(\"   Line: '{}', Bounding polygon {}\".format(line.content, points_string))\n",
    "            for word in line.words:\n",
    "                points_string = \"{\" + \", \".join([str(int(point)) for point in word.bounding_polygon]) + \"}\"\n",
    "                print(\"     Word: '{}', Bounding polygon {}, Confidence {:.4f}\"\n",
    "                      .format(word.content, points_string, word.confidence))\n",
    "    if result.tags is not None:  # タグ情報をチェックと出力\n",
    "        print(\" Tags:\")\n",
    "        for tag in result.tags:\n",
    "            print(f\"   Tag: {tag.name}, Confidence: {tag.confidence:.4f}\")\n",
    "            \n",
    "    if result.objects is not None:\n",
    "        for obj in result.objects:\n",
    "            print(f\"   Tag: {obj.name}, Confidence: {obj.confidence:.4f}\")\n",
    "            bounding_box = obj.bounding_box\n",
    "            print(f\"   Bounding box: {bounding_box.x}, {bounding_box.y}, {bounding_box.w}, {bounding_box.h}\")\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    error_details = sdk.ImageAnalysisErrorDetails.from_result(result)\n",
    "    print(\" Analysis failed.\")\n",
    "    print(\"   Error reason: {}\".format(error_details.reason))\n",
    "    print(\"   Error code: {}\".format(error_details.error_code))\n",
    "    print(\"   Error message: {}\".format(error_details.message))\n",
    "    \n",
    "#境界多角形の座標は通常、(x, y)座標のペアで表され、各ペアは多角形の頂点の位置を示します。\n",
    "#この例では、4つの頂点があり、それぞれが2D画像上の位置を表しています。座標は次の順序でリストされています：\n",
    "#第1頂点: (130, 129),第2頂点: (215, 130),第3頂点: (215, 149),第4頂点: (130, 148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d87a2b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:35 AM\n",
      "E Conference room 154584354\n",
      "#: 555-173-4547\n",
      "Town Hall\n",
      "9:00 AM - 10:00 AM\n",
      "Aaron Buaion\n",
      "Daily SCRUM\n",
      "10:00 AM 11:00 AM\n",
      "Churlette de Crum\n",
      "Quarterly NI Hands\n",
      "11.00 AM-12:00 PM\n",
      "Bebek Shaman\n",
      "Weekly stand up\n",
      "12:00 PM-1:00 PM\n",
      "Delle Marckre\n",
      "Product review\n"
     ]
    }
   ],
   "source": [
    "for line in result.text.lines:\n",
    "    print(line.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "934cbf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentTags()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c91ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
